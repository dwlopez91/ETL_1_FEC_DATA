{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import urllib\n",
    "from sqlalchemy import create_engine\n",
    "#from sqlalchemy.ext.automap import automap_base\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import PrimaryKeyConstraint\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import Column, Integer, String, Float, DateTime\n",
    "from sqlalchemy.schema import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# uploads the individual contributor datafile directly from the FEC website. \n",
    "# Opens Zipped archive and opens the text file.\n",
    "\n",
    "r = requests.get(\"https://www.fec.gov/files/bulk-downloads/2020/indiv20.zip\")\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "file=z.open('itcont.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_dict={'CMTE_ID':'str',\n",
    "             'AMNDT_IND':'str',\n",
    "             'RPT_TP':'str',\n",
    "             'TRANSACTION_PGI':'str',\n",
    "             'IMAGE_NUM':'str',\n",
    "             'TRANSACTION_TP':'str',\n",
    "             'ENTITY_TP':'str',\n",
    "             'NAME':'str',\n",
    "             'CITY':'str',\n",
    "             'STATE':'str',\n",
    "             'ZIP_CODE':'str',\n",
    "             'EMPLOYER':'str',\n",
    "             'OCCUPATION':'str',\n",
    "             'TRANSACTION_DT':'str',\n",
    "             'TRANSACTION_AMT':'str',\n",
    "             'OTHER_ID':'str',\n",
    "             'TRAN_ID':'str',\n",
    "             'FILE_NUM':'str',\n",
    "             'MEMO_CD':'str',\n",
    "             'MEMO_TEXT':'str',\n",
    "             \"SUB_ID\":\"str\"\n",
    "            }\n",
    "\n",
    "columns = list(columns_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts opened text file into a Pandas Dataframe\n",
    "\n",
    "individual_cont_staging = pd.read_csv(file, sep='|', index_col=False, names=columns, dtype=columns_dict,\n",
    "                              parse_dates=['TRANSACTION_DT'])\n",
    "\n",
    "individual_cont_staging.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the shape of the dataframe.  It's pretty BIG!\n",
    "\n",
    "individual_cont_staging.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In effort to convert the date text to date-time field, identified one record that would not convert, becuase the data\n",
    "#is not in correct format.   Removed that record from dataframe.\n",
    "\n",
    "# individual_cont_staging.set_index('TRANSACTION_DT')\n",
    "# error_table = individual_cont_staging.loc['SAN DIEGO']\n",
    "# error_table\n",
    "\n",
    "weird = individual_cont_staging['TRANSACTION_DT']=='SAN DIEGO'\n",
    "weird_df=individual_cont_staging[weird].index\n",
    "individual_cont1=individual_cont_staging.drop(weird_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the \"TRANSACTION_DT\" to date-time field\n",
    "\n",
    "individual_cont1['TRANSACTION_DT'] = pd.to_datetime(individual_cont1['TRANSACTION_DT'], format=\"%m%d%Y\")\n",
    "\n",
    "individual_cont1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the shape of the dataframe.  It's pretty BIG!\n",
    "\n",
    "individual_cont1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change dtypes of columns that should be numeric to floats.\n",
    "\n",
    "individual_cont1['TRANSACTION_AMT'] = individual_cont1['TRANSACTION_AMT'].astype(float)\n",
    "\n",
    "individual_cont1['FILE_NUM'] = individual_cont1['FILE_NUM'].astype(float)\n",
    "\n",
    "individual_cont1['TRANSACTION_AMT'] = individual_cont1['TRANSACTION_AMT'].astype(float)\n",
    "\n",
    "individual_cont1['SUB_ID'] = individual_cont1['SUB_ID'].astype(float)\n",
    "\n",
    "#Check dtype of all the columns.\n",
    "\n",
    "individual_cont1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_cont1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Postgres username, password, and database name\n",
    "ipaddress = 'localhost'\n",
    "port = '5432'\n",
    "username = 'postgres'\n",
    "password = 'password' \n",
    "dbname = 'FEC_Data'\n",
    "# A long string that contains the necessary Postgres login information\n",
    "postgres_str = f'postgresql://{username}:{password}@{ipaddress}:{port}/{dbname}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates Classes which will serve as the anchor points for our Table, loads table to Postgres and uplads the data\n",
    "\n",
    "# Base = automap_base()\n",
    "Base = declarative_base()\n",
    "engine = create_engine(postgres_str)\n",
    "#Base.prepare(engine, reflect=True)\n",
    "\n",
    "class Individuals(Base):\n",
    "    __tablename__ = 'individual_cont'\n",
    "    aid = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    CMTE_ID = Column(String(9), nullable=False)\n",
    "    AMNDT_IND = Column(String(1))\n",
    "    RPT_TP = Column(String(3))\n",
    "    TRANSACTION_PGI=Column(String(5))\n",
    "    IMAGE_NUM = Column(String(18))\n",
    "    TRANSACTION_TP=Column(String(3))\n",
    "    ENTITY_TP=Column(String(3))\n",
    "    NAME = Column(String(200))\n",
    "    CITY = Column(String(30))\n",
    "    STATE = Column(String(2))\n",
    "    ZIP_CODE = Column(String(9))\n",
    "    EMPLOYER = Column(String)\n",
    "    OCCUPATION = Column(String)\n",
    "    TRANSACTION_DT = Column(DateTime)\n",
    "    TRANSACTION_AMT = Column(Float(14))\n",
    "    OTHER_ID = Column(String(9))\n",
    "    TRAN_ID = Column(String(32))\n",
    "    FILE_NUM = Column(Float(22))\n",
    "    MEMO_CD = Column(String(1))\n",
    "    MEMO_TEXT = Column(String(100))\n",
    "    SUB_ID = Column(Float(19), nullable=False)\n",
    "#     __table_args__ = (\n",
    "#         PrimaryKeyConstraint('SUB_ID','TRAN_ID','FILE_NUM','CMTE_ID'),{})\n",
    "    \n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "individual_cont1.to_sql('individual_cont', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
